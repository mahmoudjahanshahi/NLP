{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Countries from Capitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mahmoud\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading Google News embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = KeyedVectors.load_word2vec_format('./src/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining a function to retrieve desired word embeddings**\n",
    "\n",
    "**Inputs** :  \n",
    "*embeddings*  \n",
    "*set_words*: a set of desired words\n",
    "\n",
    "**Outputs** :  \n",
    "*word_embeddings*: a dictionary containing the words and their vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings(embeddings, set_words):\n",
    "\n",
    "    word_embeddings = {}\n",
    "    for word in embeddings.vocab:\n",
    "        if word in set_words:\n",
    "            word_embeddings[word] = embeddings[word]\n",
    "    \n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laoding the word embeddings as a Python dictionary. Each of the word embedding is a 300-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('capitals.txt', 'r').read()\n",
    "set_words = set(nltk.word_tokenize(f))\n",
    "word_embeddings = get_word_embeddings(embeddings,set_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dumping the data to a pickle file**  \n",
    "(There is no need to do this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.dump(word_embeddings, open( \"word_embeddings_capitals.p\", \"wb\" ) )\n",
    "word_embeddings = pickle.load(open(\"word_embeddings_capitals.p\", \"rb\"))\n",
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Predicting relationships among words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining cosine similarity function**\n",
    "\n",
    "**Inputs** :  \n",
    "*A*: a numpy array which corresponds to a word vector  \n",
    "*B*: a numpy array which corresponds to a word vector\n",
    "\n",
    "**Outputs** :  \n",
    "*cos*: numerical number representing the cosine similarity between A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "    \n",
    "    dot = np.dot(A,B)\n",
    "    norma = np.linalg.norm(A)\n",
    "    normb = np.linalg.norm(B) \n",
    "    cos = dot / (norma*normb)\n",
    "\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining euclidean distance function**\n",
    "\n",
    "**Inputs** :  \n",
    "*A*: a numpy array which corresponds to a word vector  \n",
    "*B*: a numpy array which corresponds to a word vector\n",
    "\n",
    "**Outputs** :  \n",
    "*d*: numerical number representing the Euclidean distance between A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(A, B):\n",
    "\n",
    "    d = np.linalg.norm(A-B)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining get country function**\n",
    "\n",
    "**Inputs** :  \n",
    "*city1*: a string (the capital city of country1)  \n",
    "*country1*: a string (the country of capital1)  \n",
    "*city2*: a string (the capital city of country2)  \n",
    "*embeddings*: a dictionary where the keys are words and values are their embeddings  \n",
    "*method*: method to use in the model (either cosine similarity \"cos\" or euclidean distance \"d\")\n",
    "\n",
    "**Outputs** :  \n",
    "*countries*: a dictionary with the most likely country and its similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(city1, country1, city2, embeddings, method = \"cos\"):\n",
    "    \n",
    "    group = set([city1, country1, city2])\n",
    "    city1_emb = embeddings[city1]\n",
    "    country1_emb = embeddings[country1]\n",
    "    city2_emb = embeddings[city2]\n",
    "\n",
    "    vec = country1_emb - city1_emb + city2_emb\n",
    "\n",
    "    country = ''\n",
    "\n",
    "    if method == \"cos\":\n",
    "        similarity = -1\n",
    "        for word in embeddings.keys():\n",
    "            if word not in group:\n",
    "                word_emb = embeddings[word]\n",
    "                cur_similarity = cosine_similarity(vec, word_emb)\n",
    "                if cur_similarity > similarity:\n",
    "                    similarity = cur_similarity\n",
    "                    country = (word, similarity)\n",
    "    \n",
    "    if method == \"d\":\n",
    "        distance = 10000\n",
    "        for word in embeddings.keys():\n",
    "            if word not in group:\n",
    "                word_emb = embeddings[word]       \n",
    "                cur_distance = euclidean(vec, word_emb)\n",
    "                if cur_distance < distance:\n",
    "                    distance = cur_distance\n",
    "                    country = (word, distance)\n",
    "\n",
    "    return country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Egypt', 0.7626821)\n",
      "('Egypt', 2.4787965)\n"
     ]
    }
   ],
   "source": [
    "predict_cos = get_country('Athens', 'Greece', 'Cairo', word_embeddings, \"cos\")\n",
    "predict_d = get_country('Athens', 'Greece', 'Cairo', word_embeddings, \"d\")\n",
    "\n",
    "print(predict_cos)\n",
    "print(predict_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city1</th>\n",
       "      <th>country1</th>\n",
       "      <th>city2</th>\n",
       "      <th>country2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bern</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city1 country1    city2     country2\n",
       "0  Athens   Greece  Bangkok     Thailand\n",
       "1  Athens   Greece  Beijing        China\n",
       "2  Athens   Greece   Berlin      Germany\n",
       "3  Athens   Greece     Bern  Switzerland\n",
       "4  Athens   Greece    Cairo        Egypt"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('capitals.txt', delimiter=' ')\n",
    "data.columns = ['city1', 'country1', 'city2', 'country2']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining accuracy function**\n",
    "\n",
    "**Inputs** :  \n",
    "*word_embeddings*: a dictionary where the key is a word and the value is its embedding  \n",
    "*data*: a pandas dataframe containing all the country and capital city pairs  \n",
    "*method*: method to use in the model (either cosine similarity \"cos\" or euclidean distance \"d\")\n",
    "\n",
    "**Outputs** :  \n",
    "*accuracy*: the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(word_embeddings, data, method = \"cos\"):\n",
    "\n",
    "    num_correct = 0\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        city1 = data['city1'][i]\n",
    "        country1 = data['country1'][i]\n",
    "        city2 =  data['city2'][i]\n",
    "        country2 = data['country2'][i]\n",
    "\n",
    "        predicted_country2, _ = get_country(city1, country1, city2, word_embeddings, method)\n",
    "\n",
    "        if predicted_country2 == country2:\n",
    "            num_correct += 1\n",
    "\n",
    "    m = len(data)\n",
    "\n",
    "    accuracy = num_correct / m\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with cosine similarity method is 0.92\n",
      "Accuracy with euclidean distance method is 0.91\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = get_accuracy(word_embeddings, data, \"cos\")\n",
    "accuracy2 = get_accuracy(word_embeddings, data, \"d\")\n",
    "print(f\"Accuracy with cosine similarity method is {accuracy1:.2f}\")\n",
    "print(f\"Accuracy with euclidean distance method is {accuracy2:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
