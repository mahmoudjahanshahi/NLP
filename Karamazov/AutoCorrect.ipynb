{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**1. Data Preprocessing**](#1.-Data-Preprocessing)\n",
    "\n",
    "[**2. String Manipulations**](#2.-String-Manipulations)\n",
    "\n",
    "[**3. Combining the Edits**](#3.-Combining-the-Edits)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining process_data function\n",
    "\n",
    "**Inputs** :  \n",
    "- *file_name*: a file which is found in the current directory and will be read in\n",
    "\n",
    "**Outputs** :  \n",
    "- *words*: a list containing all the words in the corpus (text file we read) in lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_name):\n",
    "    \n",
    "    words = []\n",
    "    \n",
    "    with open(file_name , \"r\", encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "    text_lower = str.lower(text)\n",
    "    words = re.findall(r'\\w+', text_lower)\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the file and building a vocabulary set using the words list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'brothers', 'karamazov', 'by', 'fyodor']\n",
      "There are 12461 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "word_l = process_data('./src/Karamazov.txt')\n",
    "vocab = set(word_l)\n",
    "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
    "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining get_count function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word_l*: a set of words representing the corpus\n",
    "\n",
    "**Outputs** :  \n",
    "- *word_count_dict*: the wordcount dictionary where key is the word and value is its frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(word_l):\n",
    "\n",
    "    word_count_dict = {}\n",
    "\n",
    "    for w in word_l:\n",
    "        word_count_dict[w] = word_count_dict.get(w,0)+1    \n",
    "\n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the words count dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12461 key values pairs\n",
      "The count for the word 'love' is 467\n"
     ]
    }
   ],
   "source": [
    "word_count_dict = get_count(word_l)\n",
    "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
    "print(f\"The count for the word 'love' is {word_count_dict.get('love',0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining get_probs function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word_count_dict*: the wordcount dictionary where key is the word and value is its frequency\n",
    "\n",
    "**Outputs** :  \n",
    "- *probs*: a dictionary where keys are the words and the values are the probability that a word will occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(word_count_dict):\n",
    "\n",
    "    probs = {}\n",
    "    \n",
    "    for w in word_count_dict.keys():\n",
    "        probs[w] = word_count_dict[w]/sum(word_count_dict.values())\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the words probability dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of probs is 12461\n",
      "P('love') is 0.0013\n"
     ]
    }
   ],
   "source": [
    "probs = get_probs(word_count_dict)\n",
    "print(f\"Length of probs is {len(probs)}\")\n",
    "print(f\"P('love') is {probs['love']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. String Manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining delete_letter function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word*: input string\n",
    "- *verbose*: if true, prints the result\n",
    "\n",
    "**Outputs** :  \n",
    "- *delete_l*: a list of all possible strings obtained by deleting 1 character from word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word, verbose=False):\n",
    "\n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "\n",
    "    for i in range(len(word)):\n",
    "        split_l.append([word[:i],word[i:]])\n",
    "    \n",
    "    for L,R in split_l:\n",
    "        delete_l.append(L + R[1:])\n",
    "    \n",
    "    if verbose: print(f\"input word = {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "\n",
    "    return delete_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word = love, \n",
      "split_l = [['', 'love'], ['l', 'ove'], ['lo', 've'], ['lov', 'e']], \n",
      "delete_l = ['ove', 'lve', 'loe', 'lov']\n"
     ]
    }
   ],
   "source": [
    "delete_word_l = delete_letter(word=\"love\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining switch_letter function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word*: input string\n",
    "- *verbose*: if true, prints the result\n",
    "\n",
    "**Outputs** :  \n",
    "- *switches*: a list of all possible strings with one adjacent charater switched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_letter(word, verbose=False):\n",
    "    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    for i in range(len(word)-1):\n",
    "        split_l.append([word[:i],word[i:]])\n",
    "        \n",
    "    for L,R in split_l:\n",
    "        switch_l.append(L + R[1] + R[0] + R[2:])\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
    "\n",
    "    return switch_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = love \n",
      "split_l = [['', 'love'], ['l', 'ove'], ['lo', 've']] \n",
      "switch_l = ['olve', 'lvoe', 'loev']\n"
     ]
    }
   ],
   "source": [
    "switch_word_l = switch_letter(word=\"love\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining replace_letter function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word*: input string\n",
    "- *verbose*: if true, prints the result\n",
    "\n",
    "**Outputs** :  \n",
    "- *replaces*: a list of all possible strings where we replaced one letter from the original word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letter(word, verbose=False):\n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        split_l.append([word[:i],word[i:]])\n",
    "        \n",
    "    for L,R in split_l:\n",
    "        for letter in letters:\n",
    "            replace_l.append(L + letter + R[1:])\n",
    "    \n",
    "    replace_set = set(replace_l)\n",
    "    replace_set.discard(word)\n",
    "    \n",
    "    replace_l = sorted(list(replace_set))\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
    "    \n",
    "    return replace_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = love \n",
      "split_l = [['', 'love'], ['l', 'ove'], ['lo', 've'], ['lov', 'e']] \n",
      "replace_l ['aove', 'bove', 'cove', 'dove', 'eove', 'fove', 'gove', 'hove', 'iove', 'jove', 'kove', 'lave', 'lbve', 'lcve', 'ldve', 'leve', 'lfve', 'lgve', 'lhve', 'live', 'ljve', 'lkve', 'llve', 'lmve', 'lnve', 'loae', 'lobe', 'loce', 'lode', 'loee', 'lofe', 'loge', 'lohe', 'loie', 'loje', 'loke', 'lole', 'lome', 'lone', 'looe', 'lope', 'loqe', 'lore', 'lose', 'lote', 'loue', 'lova', 'lovb', 'lovc', 'lovd', 'lovf', 'lovg', 'lovh', 'lovi', 'lovj', 'lovk', 'lovl', 'lovm', 'lovn', 'lovo', 'lovp', 'lovq', 'lovr', 'lovs', 'lovt', 'lovu', 'lovv', 'lovw', 'lovx', 'lovy', 'lovz', 'lowe', 'loxe', 'loye', 'loze', 'lpve', 'lqve', 'lrve', 'lsve', 'ltve', 'luve', 'lvve', 'lwve', 'lxve', 'lyve', 'lzve', 'move', 'nove', 'oove', 'pove', 'qove', 'rove', 'sove', 'tove', 'uove', 'vove', 'wove', 'xove', 'yove', 'zove']\n"
     ]
    }
   ],
   "source": [
    "replace_l = replace_letter(word='love', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining insert_letter function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word*: input string\n",
    "- *verbose*: if true, prints the result\n",
    "\n",
    "**Outputs** :  \n",
    "- *inserts*: a list of all possible strings with one new letter inserted at every offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_letter(word, verbose=False):\n",
    "\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    for i in range(len(word)+1):\n",
    "        split_l.append([word[:i],word[i:]])\n",
    "        \n",
    "    for L,R in split_l:\n",
    "        for letter in letters:\n",
    "            insert_l.append(L + letter + R)\n",
    "            \n",
    "    insert_set = set(insert_l)\n",
    "    \n",
    "    insert_l = sorted(list(insert_set))\n",
    "\n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "    \n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = love \n",
      "split_l = [['', 'love'], ['l', 'ove'], ['lo', 've'], ['lov', 'e'], ['love', '']] \n",
      "insert_l = ['alove', 'blove', 'clove', 'dlove', 'elove', 'flove', 'glove', 'hlove', 'ilove', 'jlove', 'klove', 'laove', 'lbove', 'lcove', 'ldove', 'leove', 'lfove', 'lgove', 'lhove', 'liove', 'ljove', 'lkove', 'llove', 'lmove', 'lnove', 'loave', 'lobve', 'locve', 'lodve', 'loeve', 'lofve', 'logve', 'lohve', 'loive', 'lojve', 'lokve', 'lolve', 'lomve', 'lonve', 'loove', 'lopve', 'loqve', 'lorve', 'losve', 'lotve', 'louve', 'lovae', 'lovbe', 'lovce', 'lovde', 'lovea', 'loveb', 'lovec', 'loved', 'lovee', 'lovef', 'loveg', 'loveh', 'lovei', 'lovej', 'lovek', 'lovel', 'lovem', 'loven', 'loveo', 'lovep', 'loveq', 'lover', 'loves', 'lovet', 'loveu', 'lovev', 'lovew', 'lovex', 'lovey', 'lovez', 'lovfe', 'lovge', 'lovhe', 'lovie', 'lovje', 'lovke', 'lovle', 'lovme', 'lovne', 'lovoe', 'lovpe', 'lovqe', 'lovre', 'lovse', 'lovte', 'lovue', 'lovve', 'lovwe', 'lovxe', 'lovye', 'lovze', 'lowve', 'loxve', 'loyve', 'lozve', 'lpove', 'lqove', 'lrove', 'lsove', 'ltove', 'luove', 'lvove', 'lwove', 'lxove', 'lyove', 'lzove', 'mlove', 'nlove', 'olove', 'plove', 'qlove', 'rlove', 'slove', 'tlove', 'ulove', 'vlove', 'wlove', 'xlove', 'ylove', 'zlove']\n",
      "Number of strings output by insert_letter('love') is 126\n"
     ]
    }
   ],
   "source": [
    "insert_l = insert_letter('love', True)\n",
    "print(f\"Number of strings output by insert_letter('love') is {len(insert_l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combining the Edits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining edit_one_letter function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word*: the string/word for which we will generate all possible wordsthat are one edit away\n",
    "- *allow_switches*: if true, will add switch letter edits to the possible edits set\n",
    "\n",
    "**Outputs** :  \n",
    "- *edit_one_set*: a set of words with one possible edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_letter(word, allow_switches = True):\n",
    "\n",
    "    edit_one_set = set()\n",
    "    \n",
    "    delete_l = delete_letter(word)\n",
    "    replace_l = replace_letter(word)\n",
    "    insert_l = insert_letter(word)\n",
    "    \n",
    "    if allow_switches:\n",
    "        switch_l = switch_letter(word)\n",
    "        complete = delete_l + replace_l + insert_l + switch_l\n",
    "    \n",
    "    else:\n",
    "        complete = delete_l + replace_l + insert_l\n",
    "    \n",
    "    edit_one_set = set(complete)\n",
    "\n",
    "    return edit_one_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word = love \n",
      "edit_one_set \n",
      "['alove', 'aove', 'blove', 'bove', 'clove', 'cove', 'dlove', 'dove', 'elove', 'eove', 'flove', 'fove', 'glove', 'gove', 'hlove', 'hove', 'ilove', 'iove', 'jlove', 'jove', 'klove', 'kove', 'laove', 'lave', 'lbove', 'lbve', 'lcove', 'lcve', 'ldove', 'ldve', 'leove', 'leve', 'lfove', 'lfve', 'lgove', 'lgve', 'lhove', 'lhve', 'liove', 'live', 'ljove', 'ljve', 'lkove', 'lkve', 'llove', 'llve', 'lmove', 'lmve', 'lnove', 'lnve', 'loae', 'loave', 'lobe', 'lobve', 'loce', 'locve', 'lode', 'lodve', 'loe', 'loee', 'loev', 'loeve', 'lofe', 'lofve', 'loge', 'logve', 'lohe', 'lohve', 'loie', 'loive', 'loje', 'lojve', 'loke', 'lokve', 'lole', 'lolve', 'lome', 'lomve', 'lone', 'lonve', 'looe', 'loove', 'lope', 'lopve', 'loqe', 'loqve', 'lore', 'lorve', 'lose', 'losve', 'lote', 'lotve', 'loue', 'louve', 'lov', 'lova', 'lovae', 'lovb', 'lovbe', 'lovc', 'lovce', 'lovd', 'lovde', 'lovea', 'loveb', 'lovec', 'loved', 'lovee', 'lovef', 'loveg', 'loveh', 'lovei', 'lovej', 'lovek', 'lovel', 'lovem', 'loven', 'loveo', 'lovep', 'loveq', 'lover', 'loves', 'lovet', 'loveu', 'lovev', 'lovew', 'lovex', 'lovey', 'lovez', 'lovf', 'lovfe', 'lovg', 'lovge', 'lovh', 'lovhe', 'lovi', 'lovie', 'lovj', 'lovje', 'lovk', 'lovke', 'lovl', 'lovle', 'lovm', 'lovme', 'lovn', 'lovne', 'lovo', 'lovoe', 'lovp', 'lovpe', 'lovq', 'lovqe', 'lovr', 'lovre', 'lovs', 'lovse', 'lovt', 'lovte', 'lovu', 'lovue', 'lovv', 'lovve', 'lovw', 'lovwe', 'lovx', 'lovxe', 'lovy', 'lovye', 'lovz', 'lovze', 'lowe', 'lowve', 'loxe', 'loxve', 'loye', 'loyve', 'loze', 'lozve', 'lpove', 'lpve', 'lqove', 'lqve', 'lrove', 'lrve', 'lsove', 'lsve', 'ltove', 'ltve', 'luove', 'luve', 'lve', 'lvoe', 'lvove', 'lvve', 'lwove', 'lwve', 'lxove', 'lxve', 'lyove', 'lyve', 'lzove', 'lzve', 'mlove', 'move', 'nlove', 'nove', 'olove', 'olve', 'oove', 'ove', 'plove', 'pove', 'qlove', 'qove', 'rlove', 'rove', 'slove', 'sove', 'tlove', 'tove', 'ulove', 'uove', 'vlove', 'vove', 'wlove', 'wove', 'xlove', 'xove', 'ylove', 'yove', 'zlove', 'zove']\n",
      "\n",
      "Number of outputs from edit_one_letter('love') is 233\n"
     ]
    }
   ],
   "source": [
    "edit_one_set = edit_one_letter('love')\n",
    "print(f\"input word = love \\nedit_one_set \\n{sorted(list(edit_one_set))}\\n\")\n",
    "print(f\"Number of outputs from edit_one_letter('love') is {len(edit_one_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining edit_two_letters function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word*: the string/word for which we will generate all possible words that are two edits away\n",
    "- *allow_switches*: if true, will add switch letter edits to the possible edits set\n",
    "\n",
    "**Outputs** :  \n",
    "- *edit_two_set*: a set of strings with all possible two edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_letters(word, allow_switches = True):\n",
    "    \n",
    "    edit_two_set = set()\n",
    "    \n",
    "    edit_one_set = edit_one_letter(word, allow_switches)\n",
    "    \n",
    "    for w in edit_one_set:\n",
    "        tmp_set = edit_one_letter(w, allow_switches)\n",
    "        edit_two_set = edit_two_set.union(tmp_set)\n",
    "    \n",
    "    return edit_two_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = love \n",
      "Number of strings with edit distance of two: 24254\n",
      "First 10 strings ['aalove', 'aaove', 'aave', 'ablove', 'above', 'abve', 'aclove', 'acove', 'acve', 'adlove']\n",
      "Last 10 strings ['zwve', 'zxlove', 'zxove', 'zxve', 'zylove', 'zyove', 'zyve', 'zzlove', 'zzove', 'zzve']\n"
     ]
    }
   ],
   "source": [
    "edit_two_set = edit_two_letters('love')\n",
    "print(f\"Input word = love \\nNumber of strings with edit distance of two: {len(edit_two_set)}\")\n",
    "print(f\"First 10 strings {sorted(list(edit_two_set))[:10]}\")\n",
    "print(f\"Last 10 strings {sorted(list(edit_two_set))[-10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining get_suggestions function\n",
    "\n",
    "The suggestion algorithm follows this logic:\n",
    "\n",
    "- If the word is in the vocabulary, it suggests the word.\n",
    "- Otherwise, if there are suggestions from edit_one_letter that are in the vocabulary, it uses those.\n",
    "- Otherwise, if there are suggestions from edit_two_letters that are in the vocabulary, it uses those.\n",
    "- Otherwise, it suggests the input word.\n",
    "\n",
    "The idea is that words generated from fewer edits are more likely than words with more edits. Edits of one or two letters may 'restore' strings to either zero or one edit. This algorithm accounts for this by preferentially selecting lower distance edits first.\n",
    "\n",
    "**Inputs** :  \n",
    "- *word*: a user entered string to check for suggestions\n",
    "- *probs*: a dictionary that maps each word to its probability in the corpus\n",
    "- *vocab*: a set containing all the vocabulary\n",
    "- *n*: number of possible word corrections user wants returned in the dictionary\n",
    "- *verbose*: if true, prints the result\n",
    "\n",
    "**Outputs** :  \n",
    "- *n_best*: a list of tuples with the most probable n corrected words and their probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions(word, probs, vocab, n=2, verbose = False):\n",
    "    \n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    "    list1 = []\n",
    "    if word in vocab:\n",
    "        list1.append(word)\n",
    "    \n",
    "    list2 = []\n",
    "    for w in edit_one_letter(word):\n",
    "        if w in vocab:\n",
    "            list2.append(w)\n",
    "    \n",
    "    list3 = []\n",
    "    for w in edit_two_letters(word):\n",
    "        if w in vocab:\n",
    "            list3.append(w)\n",
    "    \n",
    "    suggestions = list1 or list2 or list3 or word\n",
    "    \n",
    "    best_words = {}\n",
    "    for w in suggestions:\n",
    "        best_words[w] = probs.get(w,0)\n",
    "    \n",
    "    best_words = Counter(best_words)\n",
    "\n",
    "    n_best = best_words.most_common(n)\n",
    "    \n",
    "    if verbose: print(\"Entered word = \", word, \"\\nSuggestions = \", suggestions,\"\\n\")\n",
    "\n",
    "    return n_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered word =  lovste \n",
      "Suggestions =  ['lost', 'lose', 'love', 'loose', 'loves'] \n",
      "\n",
      "word 0: love, probability: 0.001285\n",
      "word 1: lost, probability: 0.000237\n",
      "word 2: loves, probability: 0.000102\n"
     ]
    }
   ],
   "source": [
    "my_word = 'lovste' \n",
    "corrections = get_suggestions(my_word, probs, vocab, 3, verbose=True)\n",
    "for i, word_prob in enumerate(corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability: {word_prob[1]:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
