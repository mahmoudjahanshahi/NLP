{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting a word count given a corpus\n",
    "- Getting a word probability in the corpus\n",
    "- Manipulating strings\n",
    "- Filtering strings\n",
    "- Implementing Minimum edit distance to compare strings and to help find the optimal path for the edits\n",
    "\n",
    "[**1. Data Preprocessing**](#1.-Data-Preprocessing)  \n",
    "[**2. String Manipulations**](#2.-String-Manipulations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining process_data function\n",
    "\n",
    "**Inputs** :  \n",
    "- *file_name*: a file which is found in the current directory and will be read in\n",
    "\n",
    "**Outputs** :  \n",
    "- *words*: a list containing all the words in the corpus (text file we read) in lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_name):\n",
    "    \n",
    "    words = []\n",
    "    \n",
    "    with open(file_name , \"r\", encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "    text_lower = str.lower(text)\n",
    "    words = re.findall(r'\\w+', text_lower)\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the file and building a vocabulary set using the words list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'brothers', 'karamazov', 'by', 'fyodor']\n",
      "There are 12461 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "word_l = process_data('./src/Karamazov.txt')\n",
    "vocab = set(word_l)\n",
    "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
    "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining get_count function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word_l*: a set of words representing the corpus\n",
    "\n",
    "**Outputs** :  \n",
    "- *word_count_dict*: the wordcount dictionary where key is the word and value is its frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(word_l):\n",
    "\n",
    "    word_count_dict = {}\n",
    "\n",
    "    for w in word_l:\n",
    "        word_count_dict[w] = word_count_dict.get(w,0)+1    \n",
    "\n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the words count dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12461 key values pairs\n",
      "The count for the word 'love' is 467\n"
     ]
    }
   ],
   "source": [
    "word_count_dict = get_count(word_l)\n",
    "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
    "print(f\"The count for the word 'love' is {word_count_dict.get('love',0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining get_probs function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word_count_dict*: the wordcount dictionary where key is the word and value is its frequency\n",
    "\n",
    "**Outputs** :  \n",
    "- *probs*: a dictionary where keys are the words and the values are the probability that a word will occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(word_count_dict):\n",
    "\n",
    "    probs = {}\n",
    "    \n",
    "    for w in word_count_dict.keys():\n",
    "        probs[w] = word_count_dict[w]/sum(word_count_dict.values())\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the words probability dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of probs is 12461\n",
      "P('love') is 0.0013\n"
     ]
    }
   ],
   "source": [
    "probs = get_probs(word_count_dict)\n",
    "print(f\"Length of probs is {len(probs)}\")\n",
    "print(f\"P('love') is {probs['love']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. String Manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining delete_letter function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word*: input string\n",
    "\n",
    "**Outputs** :  \n",
    "- *delete_l*: a list of all possible strings obtained by deleting 1 character from word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word, verbose=False):\n",
    "\n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "\n",
    "    for i in range(len(word)):\n",
    "        split_l.append([word[:i],word[i:]])\n",
    "    \n",
    "    for L,R in split_l:\n",
    "        delete_l.append(L + R[1:])\n",
    "    \n",
    "    if verbose: print(f\"input word = {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "\n",
    "    return delete_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word = love, \n",
      "split_l = [['', 'love'], ['l', 'ove'], ['lo', 've'], ['lov', 'e']], \n",
      "delete_l = ['ove', 'lve', 'loe', 'lov']\n"
     ]
    }
   ],
   "source": [
    "delete_word_l = delete_letter(word=\"love\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining switch_letter function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word*: input string\n",
    "\n",
    "**Outputs** :  \n",
    "- *switches*: a list of all possible strings with one adjacent charater switched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_letter(word, verbose=False):\n",
    "    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    for i in range(len(word)-1):\n",
    "        split_l.append([word[:i],word[i:]])\n",
    "        \n",
    "    for L,R in split_l:\n",
    "        switch_l.append(L + R[1] + R[0] + R[2:])\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
    "\n",
    "    return switch_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = love \n",
      "split_l = [['', 'love'], ['l', 'ove'], ['lo', 've']] \n",
      "switch_l = ['olve', 'lvoe', 'loev']\n"
     ]
    }
   ],
   "source": [
    "switch_word_l = switch_letter(word=\"love\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining replace_letter function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word*: input string\n",
    "\n",
    "**Outputs** :  \n",
    "- *replaces*: a list of all possible strings where we replaced one letter from the original word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letter(word, verbose=False):\n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        split_l.append([word[:i],word[i:]])\n",
    "        \n",
    "    for L,R in split_l:\n",
    "        for letter in letters:\n",
    "            replace_l.append(L + letter + R[1:])\n",
    "    \n",
    "    replace_set = set(replace_l)\n",
    "    replace_set.discard(word)\n",
    "    \n",
    "    replace_l = sorted(list(replace_set))\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
    "    \n",
    "    return replace_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = love \n",
      "split_l = [['', 'love'], ['l', 'ove'], ['lo', 've'], ['lov', 'e']] \n",
      "replace_l ['aove', 'bove', 'cove', 'dove', 'eove', 'fove', 'gove', 'hove', 'iove', 'jove', 'kove', 'lave', 'lbve', 'lcve', 'ldve', 'leve', 'lfve', 'lgve', 'lhve', 'live', 'ljve', 'lkve', 'llve', 'lmve', 'lnve', 'loae', 'lobe', 'loce', 'lode', 'loee', 'lofe', 'loge', 'lohe', 'loie', 'loje', 'loke', 'lole', 'lome', 'lone', 'looe', 'lope', 'loqe', 'lore', 'lose', 'lote', 'loue', 'lova', 'lovb', 'lovc', 'lovd', 'lovf', 'lovg', 'lovh', 'lovi', 'lovj', 'lovk', 'lovl', 'lovm', 'lovn', 'lovo', 'lovp', 'lovq', 'lovr', 'lovs', 'lovt', 'lovu', 'lovv', 'lovw', 'lovx', 'lovy', 'lovz', 'lowe', 'loxe', 'loye', 'loze', 'lpve', 'lqve', 'lrve', 'lsve', 'ltve', 'luve', 'lvve', 'lwve', 'lxve', 'lyve', 'lzve', 'move', 'nove', 'oove', 'pove', 'qove', 'rove', 'sove', 'tove', 'uove', 'vove', 'wove', 'xove', 'yove', 'zove']\n"
     ]
    }
   ],
   "source": [
    "replace_l = replace_letter(word='love', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining insert_letter function\n",
    "\n",
    "**Inputs** :  \n",
    "- *word*: input string\n",
    "\n",
    "**Outputs** :  \n",
    "- *inserts*: a list of all possible strings with one new letter inserted at every offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_letter(word, verbose=False):\n",
    "\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    for i in range(len(word)+1):\n",
    "        split_l.append([word[:i],word[i:]])\n",
    "        \n",
    "    for L,R in split_l:\n",
    "        for letter in letters:\n",
    "            insert_l.append(L + letter + R)\n",
    "            \n",
    "    insert_set = set(insert_l)\n",
    "    \n",
    "    insert_l = sorted(list(insert_set))\n",
    "\n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "    \n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = love \n",
      "split_l = [['', 'love'], ['l', 'ove'], ['lo', 've'], ['lov', 'e'], ['love', '']] \n",
      "insert_l = ['alove', 'blove', 'clove', 'dlove', 'elove', 'flove', 'glove', 'hlove', 'ilove', 'jlove', 'klove', 'laove', 'lbove', 'lcove', 'ldove', 'leove', 'lfove', 'lgove', 'lhove', 'liove', 'ljove', 'lkove', 'llove', 'lmove', 'lnove', 'loave', 'lobve', 'locve', 'lodve', 'loeve', 'lofve', 'logve', 'lohve', 'loive', 'lojve', 'lokve', 'lolve', 'lomve', 'lonve', 'loove', 'lopve', 'loqve', 'lorve', 'losve', 'lotve', 'louve', 'lovae', 'lovbe', 'lovce', 'lovde', 'lovea', 'loveb', 'lovec', 'loved', 'lovee', 'lovef', 'loveg', 'loveh', 'lovei', 'lovej', 'lovek', 'lovel', 'lovem', 'loven', 'loveo', 'lovep', 'loveq', 'lover', 'loves', 'lovet', 'loveu', 'lovev', 'lovew', 'lovex', 'lovey', 'lovez', 'lovfe', 'lovge', 'lovhe', 'lovie', 'lovje', 'lovke', 'lovle', 'lovme', 'lovne', 'lovoe', 'lovpe', 'lovqe', 'lovre', 'lovse', 'lovte', 'lovue', 'lovve', 'lovwe', 'lovxe', 'lovye', 'lovze', 'lowve', 'loxve', 'loyve', 'lozve', 'lpove', 'lqove', 'lrove', 'lsove', 'ltove', 'luove', 'lvove', 'lwove', 'lxove', 'lyove', 'lzove', 'mlove', 'nlove', 'olove', 'plove', 'qlove', 'rlove', 'slove', 'tlove', 'ulove', 'vlove', 'wlove', 'xlove', 'ylove', 'zlove']\n",
      "Number of strings output by insert_letter('love') is 126\n"
     ]
    }
   ],
   "source": [
    "insert_l = insert_letter('love', True)\n",
    "print(f\"Number of strings output by insert_letter('love') is {len(insert_l)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
